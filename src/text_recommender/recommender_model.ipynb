{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending a text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general philosophy:\n",
    " - convert input text to a vector using bert\n",
    " - use co-sine similarity to create a list of recommendations\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/cefr_texts_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi!\\nI've been meaning to write for ages and f...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿It was not so much how hard people found the ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keith recently came back from a trip to Chicag...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Griffith Observatory is a planetarium, and...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LRB- The Hollywood Reporter -RRB- It's offici...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Hi!\\nI've been meaning to write for ages and f...    B2\n",
       "1  ﻿It was not so much how hard people found the ...    B2\n",
       "2  Keith recently came back from a trip to Chicag...    B2\n",
       "3  The Griffith Observatory is a planetarium, and...    B2\n",
       "4  -LRB- The Hollywood Reporter -RRB- It's offici...    B2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = X\n",
    "embeddings = model.encode(text_data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19669095, -0.05202733,  0.98705184, ..., -0.16426736,\n",
       "        -0.30259478, -0.41186592],\n",
       "       [-0.17723879, -0.6763533 ,  1.0110435 , ..., -0.05299941,\n",
       "         0.35358116, -0.08957867],\n",
       "       [ 0.5804109 , -0.0420664 ,  0.23823978, ...,  0.5205901 ,\n",
       "         0.09691685, -0.6945751 ],\n",
       "       ...,\n",
       "       [-0.27873665, -0.67466617,  0.49661222, ..., -0.799724  ,\n",
       "        -0.01645303, -0.76547444],\n",
       "       [ 0.09076631, -0.5078224 ,  0.45367232, ...,  0.2046578 ,\n",
       "         0.6846901 , -0.44405267],\n",
       "       [ 0.04727781, -0.14412397,  1.2648243 , ..., -0.63194317,\n",
       "        -0.59732926, -0.86583316]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = pickle.load(open('embeddings.pkl', 'rb'))\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.000000\n",
       "1       0.672991\n",
       "2       0.525985\n",
       "3       0.459844\n",
       "4       0.597655\n",
       "          ...   \n",
       "1489    0.386422\n",
       "1490    0.665632\n",
       "1491    0.553183\n",
       "1492    0.597572\n",
       "1493    0.547127\n",
       "Name: 0, Length: 1494, dtype: float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_data = pd.DataFrame(cosine_similarity(embeddings))\n",
    "cos_sim_data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_recomm =cos_sim_data.loc[10].sort_values(ascending=False).index.tolist()[1:6]\n",
    "movies_recomm =  data['text'].loc[index_recomm].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.439560\n",
       "1       0.454898\n",
       "2       0.508430\n",
       "3       0.489645\n",
       "4       0.351325\n",
       "          ...   \n",
       "1489    0.502563\n",
       "1490    0.572604\n",
       "1491    0.552293\n",
       "1492    0.462262\n",
       "1493    0.537957\n",
       "Name: 0, Length: 1494, dtype: float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Astronauts are extraordinary individuals who embark on the most incredible adventures humanity has ever known. These intrepid explorers venture into the vastness of space, pushing the boundaries of human knowledge and understanding. Let's delve into the captivating world of astronauts and discover the amazing work they do.\"\n",
    "text = model.encode(text)\n",
    "text = np.array(text).reshape(1, -1)\n",
    "cos_sim_data = pd.DataFrame(cosine_similarity(text,embeddings))\n",
    "cos_sim_data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_recomm =cos_sim_data.loc[0].sort_values(ascending=False).index.tolist()[1:6]\n",
    "text_recomm =  data['text'].loc[index_recomm].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you need to map a billion stars ? A billion-pixel camera certainly helps.\n",
      "Scientists hope to glean more clues about the origin and evolution of the universe, and in particular our own galaxy, after a camera of this incredible scale -- fitted to the Gaia space telescope -- was launched Thursday.\n",
      "Gaia, which lifted off from French Guiana, has been tasked with mapping the Milky Way in greater detail than ever before.\n",
      "Designed and built by Astrium for the European Space Agency -LRB- ESA -RRB-, the makers say the telescope is so sensitive that it could measure a person's thumbnail from the Moon, or to put it another way, detect the width of a human hair from 1,000 km -LRB- 620 miles -RRB- away.\n",
      "The mission's aim is to build a three-dimensional picture of our galaxy, measuring precise distances to a billion stars. Even this is a small fraction of the Milky Way, as astronomers believe there are at least 100 billion stars in our galaxy.\n",
      "Tens of billions like Earth, study says\n",
      "Astrium says Gaia is also expected to log a million quasars beyond the Milky Way, and a quarter of a million objects in our own solar system, including comets and asteroids.\n",
      " It can do it with incredible accuracy. It's the biggest camera ever put into space, said Ralph Cordey, head of science and exploration at Astrium.\n",
      "He said the spacecraft cost 400 million euros -LRB- $549 million -RRB- to build, but the total cost of the mission would come to 740 million euros -LRB- $1.02 billion -RRB- when the expense of the launch and running the mission for its projected five-year lifetime are included.\n",
      "If successful, Gaia will add to the knowledge gained from NASA's Hubble Space Telescope, which is still in operation, and ESA's Hipparcos satellite, which gathered data until 1993.\n",
      "Hubble spots azure planet where it may rain glass\n",
      "The value of putting a billion-pixel camera into space has been championed by Robert Massey from the UK's Royal Astronomical Society.\n",
      " Gaia is an amazingly ambitious mission, he said.\n",
      " Until now astronomers have relied on very indirect methods to gauge the distance to all but the nearest stars, meaning that the foundation on which we build a map of the universe is surprisingly weak.\n",
      " Building on the work of the pioneering Hipparcos satellite that mapped the stellar neighbourhood in the 1990s, Gaia will be used to carry out work analogous to the cartographers who surveyed the Earth in the 19th and 20th centuries, building up the first accurate charts of the cosmos and helping us better understand the structure, history and fate of the galaxy we live in. \n",
      "One of Gaia's objectives is to help in the hunt for exoplanets -- new worlds beyond our own solar system.\n",
      "NASA's Kepler mission has so far confirmed the existence of 167 exoplanets with hundreds more being investigated, but Cordey anticipates Gaia will likely discover thousands of new planets, while further missions will be able to uncover more detail about them.\n",
      "In a recent interview with CNN, George Whitesides, CEO of Virgin Galactic -- the company planning to take tourists into space -- said he thought that within a lifetime it would be possible to detect seasons on far-off worlds.\n",
      "He may have not have too long to wait, as Astrium is already working on design concepts to examine exoplanet atmospheres -- which may provide signs of seasonal variations.\n",
      " We are designing missions that could probably do that very thing -- it's not science fiction, said Cordey.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text_recomm[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
